{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "To more conveniently use arrays in Python, we will use the PyTorch numerical computing framework. To install it, go to https://pytorch.org/get-started and follow the instructions for your system. Once we have PyTorch installed, we import `torch` to use PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14, 14],\n",
      "        [ 4,  1]])\n",
      "tensor([[14, 14],\n",
      "        [ 1, -5]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[8, 4], [-2, -9]])\n",
    "# if I have only one dimension, I use this one to add both rows of a\n",
    "b = torch.tensor([6, 10])\n",
    "# regular element-wise addition\n",
    "c = torch.tensor([[6, 10], [3,4]])\n",
    "print(a + b)\n",
    "print(a + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6, 10])\n",
      "tensor([[ 6],\n",
      "        [10]])\n",
      "tensor([[14, 10],\n",
      "        [ 8,  1]])\n",
      "torch.Size([2])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[8, 4], [-2, -9]])\n",
    "b = torch.tensor([6, 10])\n",
    "print(b)\n",
    "print(b[:, None]) # this returns \n",
    "#tensor([[ 6],\n",
    "#        [10]])\n",
    "# 2 rows 1 col\n",
    "# None adds one dimension-axis\n",
    "# Now I have 2 rows 1 col\n",
    "# So I use the element from the first row to add both elements of the first row of a \n",
    "# and the first element of the 2nd row to add both elements of the second row of a.\n",
    "print(a + b[:, None])\n",
    "print(b.shape) # torch.Size([2]) (meaning it has only one dimension and 2 elements in that dimension)\n",
    "print(a.shape) # torch.Size([2, 2]) meaning it has two dimensions and 2 elements per dimension\n",
    "\n",
    "#The first element of the tuple, 2, represents the size of the tensor along the first dimension (number of rows), \n",
    "#and the second element, 3, represents the size of the tensor along the second dimension (number of columns).\n",
    "\n",
    "#So, the output of print(a.shape) will be (2, 3).\n",
    "\n",
    "#You can also access individual elements of the shape tuple using indexing. For example, a.shape[0] gives the size of \n",
    "#the tensor along the first dimension, and a.shape[1] gives the size along the second dimension."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the following if necessary.\n",
    "* `matplotlib` for plotting. Install it using `pip install matplotlib`. Or `conda install matplotlib` if you prefer.\n",
    "* `tqdm` has a stupid name but provides a nice progress bar. `pip install tqdm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in tqdm(range(10)):\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# I was initially getting this error\n",
    "#TypeError                                 Traceback (most recent call last)\n",
    "#Cell In[11], line 1\n",
    "#----> 1 for i in tqdm(range(10)):\n",
    "#      2     time.sleep(0.5)\n",
    "\n",
    "#TypeError: 'module' object is not callable\n",
    "\n",
    "#The error you encountered, 'module' object is not callable, suggests that you might have a naming conflict or have \n",
    "# imported the wrong module.\n",
    "\n",
    "# In this case, it seems like you have imported the tqdm module itself INSTEAD OF THE tqdm FUNCTION FROM THE MODULE.\n",
    "# The error message indicates that you are trying to use tqdm as a callable, which is not possible when it refers to \n",
    "# the module object.\n",
    "\n",
    "# solution: from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messing with Tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important data structure in PyTorch is the `Tensor`, which is an array of numbers, all of the same type, usually some kind of floating-point number. In the machine learning community, such arrays are often called *tensors*, even when they aren't being used to represent mathematical [tensors](https://en.wikipedia.org/wiki/Tensor), which are linear maps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create `Tensor`s by passing in Python `tuple`s or `list`s to the `tensor` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor((1, 2, 3, 4))\n",
    "b = torch.tensor((( 5,  6,  7,  8),\n",
    "                  (-5, -6, -7, -8)))\n",
    "c = torch.tensor([[1],\n",
    "                  [2]])\n",
    "\n",
    "# In the statement a = torch.tensor((1, 2, 3, 4)), torch represents the module, while tensor is a factory function or \n",
    "# constructor within the torch module.\n",
    "\n",
    "# In PyTorch, torch is the top-level package for the PyTorch library. It provides a variety of functionality for tensor \n",
    "# computations, neural networks, and other machine learning operations.\n",
    "\n",
    "# The tensor function is one of the many functions provided by the torch module. It is used to create a new tensor object. \n",
    "# In the given example, the torch.tensor() function is called with (1, 2, 3, 4) as its argument, which creates a new \n",
    "# tensor object a with the values (1, 2, 3, 4)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All `Tensor`s have `shape`s. Here are their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4]), torch.Size([2, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add, subtract, and negate `Tensor`s using + and -."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 4, 6, 8]), tensor([0, 0, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + a, a - a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is applied automatically where it's unambiguous. (Read the 2_math_review notebook if you are unsure what broadcasting does.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  8, 10, 12],\n",
       "        [-4, -4, -4, -4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b\n",
    "# we add the a row to each of the 2 b rows (col by col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication can be done using the `@` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 70, -70])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b @ a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Element-wise multiplication is automatically broadcasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5,  12,  21,  32],\n",
       "        [ -5, -12, -21, -32]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting depends on the orientation of the vector whether is a column or row vector\n",
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5,   6,   7,   8],\n",
       "        [-10, -12, -14, -16]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c * b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select elements or slices of `Tensor`s using`[index]`. This `index` can be a variety of things. I'll show you a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = (0, 0)\n",
    "b[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5, -6, -7, -8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1, :] # second row (0 indexed), the whole col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, -6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 1] # all rows, second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  6],\n",
       "        [-5, -6]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, :2] # from start till 2 -> :2 ... from 2 till end 2: ..... #0:3:2 from 0 to 3 (exclusive I believe) with setps of 2\n",
    "# all rows, and cols 0 - 1 (2 is exclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  7],\n",
       "        [-5, -7]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, :3:2] #0:3:2 from 0 to 3 (exclusive I believe) with setps of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [-7, -8]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, 2:] # all rows and from 2 to end (inclusive) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See PyTorch's [Tensor indexing API](https://pytorch.org/cppdocs/notes/tensor_indexing.html) for more examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent\n",
    "\n",
    "Gradient descent is an optimization method that adjusts the parameters of a differentiable function that captures some sort of \"loss,\" or the error of an estimation, in order to optimize it. [Here](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) is a nice YouTube playlist about it by 3Blue1Brown. I'll demonstrate it through a regression task. Regression is predicting a real number or real array.\n",
    "\n",
    "Suppose there were some function $f$ that maps real numbers to real numbers. That is, $f: \\mathbb{R} \\to \\mathbb{R}$. Let's make an $f$ that is actually $e^x +$ some random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: torch.Tensor) -> torch.Tensor:\n",
    "    # input parameter: instead of data_type param_name is param_name: data_type\n",
    "    \"\"\"\n",
    "    :returns: e^x + some random noise\n",
    "\n",
    "\n",
    "    The notation you provided is a function signature in Python. Let's break it down:\n",
    "\n",
    "    def: This keyword is used to define a function in Python.\n",
    "    f: This is the name of the function.\n",
    "    (x: torch.Tensor): This part specifies the function's input parameter. In this case, the parameter is named x, and \n",
    "    the torch.Tensor indicates the expected type of the parameter. torch.Tensor is a type hint indicating that the \n",
    "    parameter x should be a tensor object from the PyTorch library.\n",
    "    -> torch.Tensor: This part indicates the return type of the function. In this case, the torch.Tensor type hint \n",
    "    suggests that the function will return a tensor object from the PyTorch library.\n",
    "    Overall, this function signature indicates that the function f takes a parameter x of type torch.Tensor and \n",
    "    returns a value of type torch.Tensor.\n",
    "    \"\"\"\n",
    "    return torch.exp(x) + 0.1 * torch.randn(len(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's pretend we don't know what $f$ is. We only see some examples of $x$ mapped to $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8mUlEQVR4nO3df3RU9Z3/8dcAIUE2GQwIM8hP0SohtvJDhOqigCBYqXY9W7XiUk8PZ2HBqqzfKt26mHVb9Gy3ZbsqVA9CNQtyukiRg2WLR4JVwqL8aKWpqGwUFhNZfs0gmh8kn+8f6Uwzyfy4d+bO3PnxfJyTc8ydz0zu9RLum8/n/X5/PMYYIwAAAJf0cPsEAABAYSMYAQAAriIYAQAAriIYAQAAriIYAQAAriIYAQAAriIYAQAAriIYAQAArurl9glY0d7erk8++USlpaXyeDxunw4AALDAGKOzZ89q8ODB6tEj9vxHTgQjn3zyiYYOHer2aQAAgCQcPXpUQ4YMifl6TgQjpaWlkjoupqyszOWzAQAAVgSDQQ0dOjT8HI8lJ4KR0NJMWVkZwQgAADkmUYoFCawAAMBVBCMAAMBVBCMAAMBVBCMAAMBVBCMAAMBVBCMAAMBVBCMAAMBVBCMAAMBVOdH0DAAA2NPWbrSn/pSOn23SwNISTRxZrp49snN/N4IRAADyzLaDDaraUqeGQFP4mN9bomVzKjSr0u/imUXHMg0AAHlk28EGLazeFxGISFJjoEkLq/dp28EGl84sNoIRAADyRFu7UdWWOpkor4WOVW2pU1t7tBHuIRgBACBP7Kk/1W1GpDMjqSHQpD31pzJ3UhaQMwIAQB5oazd668MTlsb++k9LNdmS1OoxxmTXXE0UwWBQXq9XgUBAZWVlbp8OAABZJVrCqhXpTmq1+vxmmQYAgBwWK2HVimxJaiUYAQAgR8VLWLUiW5JaCUYAAMhRiRJWrciGpFaCEQAActTxs6kFIun6LLsIRgAAyFEDS0uy8rPsIhgBACDHtLUb1R4+qcbAFyrv21uxinM9knxlxfKVlcQd4/d27F3jFvqMAACQQ6yW8YaCj8e+PkaStLB6nzxSRLJraMyyORWu9hthZgQAgBxhp4zX5y3RyrnjNKvSr1mVfq2cO04+b0nMMW5iZgQAgBxgpYy3vG+RHr1ljHxlJd26q86q9GtGhU976k/p+NkmDSztPsYtBCMAAOQAK2W8p861yldWosmj+kd9vWcPT8RrodwTt4MTghEAAHKA1dJbq+Oi5Z6kuz18LOSMAACQA6yW3loZFyv3xK328AQjAADkgIkjy+X3pl6iGy/3xK328AQjAADkgJ49PFo2p0KSugUkdkp0E+WeuNEenmAEAIAc4USJrtO5J04ggRUAgBySaomuk7knTrE1M7J8+XJdffXVKi0t1cCBA3Xbbbfp0KFDcd9TU1Mjj8fT7eu9995L6cQBAChUoRLdW6+6WJNH9bdVjutU7omTbAUjO3fu1KJFi7R7925t375d58+f18yZM3Xu3LmE7z106JAaGhrCX5dddlnSJw0AAJLjVO6Jk2wt02zbti3i+zVr1mjgwIHau3evpkyZEve9AwcOVL9+/WyfIAAAcFYo96RrnxGfS31GUsoZCQQCkqTy8sRTOWPHjlVTU5MqKir0gx/8QFOnTo05trm5Wc3NzeHvg8FgKqcJAAC6yKb28EkHI8YYLVmyRNddd50qKytjjvP7/Xr22Wc1fvx4NTc368UXX9T06dNVU1MTczZl+fLlqqqqSvbUAACABV3bw7vFY4xJqqvJokWLtHXrVr355psaMmSIrffOmTNHHo9Hr7zyStTXo82MDB06VIFAQGVlZcmcLgAAOaut3WTFDIZdwWBQXq834fM7qZmR++67T6+88oreeOMN24GIJE2aNEnV1dUxXy8uLlZxcXEypwYAQF7Jpj1k0sVWNY0xRosXL9bLL7+s119/XSNHjkzqh+7fv19+f378DwQAIF2ybQ+ZdLE1M7Jo0SKtW7dOmzdvVmlpqRobGyVJXq9Xffr0kSQtXbpUx44d0wsvvCBJWrFihUaMGKExY8aopaVF1dXV2rhxozZu3OjwpQAAkD8S7SHjUcceMjMqfDmxZBOPrWBk5cqVkqQbbrgh4viaNWv07W9/W5LU0NCgI0eOhF9raWnRQw89pGPHjqlPnz4aM2aMtm7dqptvvjm1MwcAII/Z2UMmG5JQU2ErGLGS67p27dqI77/3ve/pe9/7nq2TAgCg0GXjHjLpwkZ5AABkoWzcQyZd2CgPAACXxCvZDe0h0xhoipo34lFHx9RM7iGTLgQjAAC4IFHJbmgPmYXV++SRIgISt/aQSReWaQAAyJC2dqPawyf1T1v+oAUWSnZDe8j4vJFLMT5viVbOHZc3fUaYGQEAIAOizYR0FZr9+P6md/VFa7t8ZSWaUeHLmj1k0oVgBACANAs1L7O6/8qpc616cMMBSfnXbTUalmkAAEijeM3LrMi3bqvREIwAAJBGiZqXJRIKYqq21KmtPdmQJrsRjAAAkEZONCXr3G01HxGMAACQRk42JcuHbqvREIwAAJBGoeZlTtS+5EO31WgIRgAASKNQ8zJJMQOSe786XOV9e8d83aOOqpp86LYaDcEIAABpFqt5md9bolVzx2nZ1yv1o29USuoesORbt9VoPMbKVrwuCwaD8nq9CgQCKisrc/t0AABISry9aKTELeJzjdXnN8EIAABZJFHAkkusPr/pwAoAQBbp2cOjyaP6u30aGUXOCAAAcBXBCAAAcBXBCAAAcBU5IwAAOCCfEk8zjWAEAIAU5VtJbqaxTAMAQAq2HWzQwup93XbmbQw0aWH1Pm072ODSmeUOghEAAJLU1m5UtaVO0Rp2hY5VbalTW3vWt/RyFcEIAABJ2lN/qtuMSGdGUkOgSXvqT2XupHIQwQgAAEk6fjZ2IJLMuEJFMAIAQJIGlpYkHiTpxNlmlmriIBgBACBJE0eWy+8t6bbTblePb/2jrnvydZJZYyAYAQAgST17eLRsToUkJQxIqK6JjWAEAIAUzKr0a+XccfJ54y/ZUF0TG8EIAAA2tbUb1R4+qc0Hjqn28EnNqPDpzYen6dGvjY77PqproqMDKwAANsTrtjqgtNjSZ1BdE4mZEQAALErUbfWjE+csfY7VKpxCQTACAIAFVrqtrt9zRL6y2NU1HnXMokwcWZ6ek8xRBCMAAFhgpdtqY7BZd00cJql7dU3o+2VzKtjNtwuCEQAALLCa5zFiwAVRq2t83hKtnDuOXXyjIIEVAAALrOZ5DCwt0eRR/TWjwqc99ad0/GyTBpZ2LM0wIxIdwQgAABaEuq02Bpqi5o141DH7EcoH6dnDo8mj+mf0HHMVyzQAAFgQr9sq+SCpIRgBAMCiWN1WyQdJDcs0AADYMKvSTz6IwwhGAACwiXwQZ7FMAwAAXEUwAgAAXEUwAgAAXEUwAgAAXEUwAgAAXEU1DQCgoLW1m4RlulbGIHkEIwCAgrXtYIOqttRF7Mbr95Zo2ZyKcAMzK2OQGo8xJlqL/awSDAbl9XoVCARUVlbm9ukAAPLAtoMNWli9r9s+M6H5jpVzx0lSwjEEJLFZfX4zMwIAKDht7UZVW+qibnhn1BFsPPbKHyR54o6p2lKnGRU+lmxSRAIrAKDg7Kk/FbHs0pWR1BhsVmMw/piGQJP21J9y/gQLDMEIAKDgHD8bO8hw87MKFcEIAKDgDCwtSTzIhc8qVAQjAICCM3FkufzeEsXL9PCW9FJ5394xx3jUUVUzcWR5Gs6wsBCMAAAKTs8eHi2bUyFJMYONQNN5nTrXEjWBNfSeZXMqSF51AMEIACDntLUb1R4+qc0Hjqn28Em1tdvvUjGr0q+Vc8fJ57W/zOLzllDW6yBKewEAOcXJJmSzKv2aUeHT7sMntWjdPp35ojXm2PK+RXr0ljHyldGB1WnMjAAAckaoUVnXstzGQJMWVu/TtoMNtj+zZw+PevTwxA1EJOnUuVb5yko0eVR/AhGH2QpGli9frquvvlqlpaUaOHCgbrvtNh06dCjh+3bu3Knx48erpKREl1xyiVatWpX0CQMAClOiRmVSRxOyZJZsrJbnUsabHraCkZ07d2rRokXavXu3tm/frvPnz2vmzJk6d+5czPfU19fr5ptv1l/+5V9q//79+v73v6/vfve72rhxY8onDwAoHFYalSXbhMxqeS5lvOlhK2dk27ZtEd+vWbNGAwcO1N69ezVlypSo71m1apWGDRumFStWSJJGjx6td955Rz/+8Y91++23J3fWAICCk87Zi1Cpb2OgKWb1jI8y3rRJKWckEAhIksrLY9+c2tpazZw5M+LYTTfdpHfeeUetrfHX5wAACEnn7EW8Ul/KeNMv6WDEGKMlS5bouuuuU2VlZcxxjY2NGjRoUMSxQYMG6fz58zpx4kTU9zQ3NysYDEZ8AQAKW6JGZak2IYtV6ksZb/olXdq7ePFi/f73v9ebb76ZcKzHE/lHxxgT9XjI8uXLVVVVleypAQDyUGj2YmH1PnmkiOUUp2YvQqW+e+pP6fjZJg0spYw3E5KaGbnvvvv0yiuvaMeOHRoyZEjcsT6fT42NjRHHjh8/rl69eql///5R37N06VIFAoHw19GjR5M5TQBAnsnE7EXPHh5NHtVft151MWW8GWJrZsQYo/vuu0+bNm1STU2NRo4cmfA9kydP1pYtWyKO/eY3v9GECRNUVFQU9T3FxcUqLi62c2oAgALB7EX+sRWMLFq0SOvWrdPmzZtVWloanvHwer3q06ePpI5ZjWPHjumFF16QJC1YsEBPPfWUlixZovnz56u2tlarV6/W+vXrHb4UAEChCM1eID/YWqZZuXKlAoGAbrjhBvn9/vDXhg0bwmMaGhp05MiR8PcjR47Uq6++qpqaGl111VV6/PHH9bOf/YyyXgAAIEnymFA2aRYLBoPyer0KBAIqKytz+3QAAIAFVp/f7E0DAABcxa69AICs0tZuSE4tMAQjAICsse1gg6q21EXsQeP3lmjZnApHynYJdLITwQgAICtsO9ighdX7uu0N0xho0sLqfSn3EUl3oIPkkTMCAHBEW7tR7eGT2nzgmGoPn1Rbu/X6iLZ2o6otdVE3qQsdq9pSZ+szOwsFOl13/Q0FOtsONiT1uXAGMyMAgJSlOuuwp/5Ut0ChMyOpIdCkPfWnbPcXSRToeNQR6Myo8LFk4xJmRgAAKXFi1uH42diBSDLjOrMT6MAdBCMAgKQ5tbwysLQk7utWxsVaJkpnoANnsEwDAEiaU8srE0eWy+8tUWOgKWpg41HHZngTR5ZHfX+0ZSJfWbHumjhMrW3tlq7FakAE5xGMAACS5tSsQ88eHi2bU6GF1fvkkSICklAWx7I5FVFzOmJW4QSb9dPXPkh4bokCHaQfyzQAgKQ5sbwSMqvSr5Vzx8nnjRzr85bELOuNt0xkRaJAB5nBzAgAIGmpLq90NavSrxkVPsuNyRItEyXio89IViAYAQAkLZXllXifabV8N9mk08VTL9W1lw6gA2uWYJkGAJCSZJZXnJJs0ullg/5Ck0f1JxDJEsyMAABSZnV5xem9YRItE8VC5Ux2IRgBADgi0fJKOvaGibdMFA2VM9mJZRoAQNqlc2+YWMtEXVE5k72YGQEApFUm9obpukz00YnPtX7PETUGOzVBo3ImaxGMAADSKp2b4HXWdZlo8bRLHc1PQfoQjAAA0spq+e2v/7RU41TQYKdEGO4iGAEApJXVypUXaj/WC7Ufp5zUitxDAisAIK1C5bdW5zqcSGpFbiEYAQCkVaj8VpKlgCSU6Fq1pU5t7cnuOoNcQjACAEg7q+W3IZ2TWpH/yBkBAGRE5/LbXx9s0Au1Hyd8T7J7zyC3MDMCAMiYUIXLbIvJqbRtLwwEIwCAjEuU1OpRR6t42rYXBoIRAEDGxUtqpW174SEYAQC4IlZSq89bopVzx9FnpICQwAoAcE3XPWVo216YCEYAAK6ibTtYpgEAAK4iGAEAAK5imQYAkDZt7YZ8ECREMAIASIttBxtUtaVODYE/d1FlR15EwzINAMBx2w42aGH1vohARGJHXkRHMAIAcFRbu1HVljpF22+XHXkRDcEIAMBRe+pPdZsR6SyZHXnb2o1qD5/U5gPHVHv4JIFMniFnBADyRLYki1rdadfqOHJP8h/BCADkgWx6YFvdadfKuFDuSdd5kFDuCW3j8wPLNACQ47ItWdSpHXnJPSkcBCMAkMOy8YHt1I686cg9QXYiGAGAHJatD2wnduR1OvcE2YucEQDIYXYf2JlMck11R14nc0+Q3QhGACCH2Xlgu5HkmsqOvKHck8ZAU9RlKI86ZloS5Z4g+7FMAwA5zGqy6OlzLVmV5GqFU7knyH4EIwCQw6w8sB/92mg9vjW7klytciL3BNmPZRoAyHGhB3bXJRjfn5ZgvH16W05yTXZJJZ1SzT1B9iMYAYA8EO+BvfnAMUuf4UaSq1Wp5J4g+xGMAECeiPXAzvYkV4CcEQDIc/mc5Ir8QDACAHnOiSRXI+n7m97Vpv3smgvnEYwAQAFIVJVyYd/iuEmuknTqXKse3HBAdz23W9c9+TozJXAMOSMAUCCcSHINaQg0aUH1Pn3n2hG6scKXFUmuyF0EIwBQQFJNcu1q9VsfafVbH5HkipSwTAMABa6t3ai93ahfn6KkP4MkV6SCmREAKGDRSnmTYdSRDFu1pU4zKnws2cAWZkYAoEBtO9gQtZQ3WZ07uQJ2EIwAQAFqazeq2hK9lDfEW9JL5X17x+xPEkuokytgle1g5I033tCcOXM0ePBgeTwe/epXv4o7vqamRh6Pp9vXe++9l+w5AwBStKf+VMIZkUDTec2bPEJS9/4k8SSbDIvCZTsYOXfunL7yla/oqaeesvW+Q4cOqaGhIfx12WWX2f3RAACHWJ29GDHggqj9SaIJdXKdOLI8xbNDobGdwDp79mzNnj3b9g8aOHCg+vXrZ/t9AADn2dmvZvKo/uH+JNvrGvX8Wx/JI0Us8YRmTpbNqSB5FbZlLGdk7Nix8vv9mj59unbs2BF3bHNzs4LBYMQXAMC+tnaj2sMntflAZBt3q/vVhGY5Qv1J/nHOGK2K08mVPiNIRtpLe/1+v5599lmNHz9ezc3NevHFFzV9+nTV1NRoypQpUd+zfPlyVVVVpfvUACCntbWbqN1UQxLtwLtsToUWVu+zPcsRr5MrkAyPMSbp3Y48Ho82bdqk2267zdb75syZI4/Ho1deeSXq683NzWpubg5/HwwGNXToUAUCAZWVlSV7ugCQNxIFGqGy3a5/wYfChdAsRqLPAVIRDAbl9XoTPr9daXo2adIkVVdXx3y9uLhYxcXFGTwjAMgdsQKNUBfUp781Vo9v/WPMHXg7NydjlgPZwJVgZP/+/fL7ibgBwK54/UFCgcYPNh/UqXOtMT+jc3OyyaP6x9yvBsgU28HIZ599pg8//DD8fX19vQ4cOKDy8nINGzZMS5cu1bFjx/TCCy9IklasWKERI0ZozJgxamlpUXV1tTZu3KiNGzc6dxUAkCMS5Xkkkqg/iJHiBiKd0ZwM2cJ2MPLOO+9o6tSp4e+XLFkiSZo3b57Wrl2rhoYGHTlyJPx6S0uLHnroIR07dkx9+vTRmDFjtHXrVt18880OnD4A5A4n8jOcDCBoToZskVICa6ZYTYABgGxlNaE0kdrDJ3XXc7sTjivv21unz7VEXc7xqKMU982Hp5EbgrSy+vxmbxoASLNEeR5SR0JpqAdIPFb7g/zzrZXh77u+LtGcDNmFYAQA0sxKnofV3W579vBo2ZwKSfEDjZu/7I/axp3mZMhGrlTTAEAhsZrnYXXcrMqOQKNr/omvS/4JZbvIFQQjAJBmdvaBscpqoEHZLnIBwQgApFkoz6Mx0BQ3oTS0D4zV8l8CDeQLghEASLNQnoeVfWBoz45CRAIrAGRAKM8jXkJpqPy3a7JrqM37toMNmTxlIGOYGQGADImX52GlzXtoPxkSUJFvCEYAIINi5XnYKf8lTwT5hmUaAMgCTpf/ArmEYAQAskA6yn+BXEEwAgBZwGqb91D5L5BPCEYAIAtYbfNO8iryEcEIAGQJK+W/QD6imgYALLDaFTVV7CeDQkQwAgAJZLorKm3eUWhYpgGAOOiKCqQfwQgAxJCoK6rU0RW1rT3aCABWEYwAQAx2uqICSB7BCABE0dZu9NaHJyyNpSsqkBoSWAEUvK6VMqfPtejxrXVxZ0U6S7UraqYqdYBsRTACoKBFq5SxyqOOHiCpdEXNdKUOkI1YpgFQsGJVyljhRFdUKnWADgQjAPJaW7tR7eGT2nzgmGoPnwxXvsSrlLEi1a6oVOoAf8YyDYC8FW0JxFdWrLsmDlNrW3tSMyKStHjqKD044/KU8jrsVOrQAA35jmAEQF4KLYF0nVdoDDbrp699kNJnX3vpRSknmFqtwKFSB4WAYARA3kl1CSaWZBJWY1XKWK3ASbVSB8gFBCMA8k6iJZBkJJOwGq9SZkaFT35viRoDTVGDpq6BD+W/yGcEIwDyTjqWNnwWym07BwwfnfhcK157v/sy0Z8qZVbOHadlcyq0sHqfPFLEuK6BD+W/yHcEIwDyTqpLG35viR792mhd2Lc47kxE1+Bj/Z4jagzGD4SMOoKNqi11evPhaVo5d1z3JNtOgUbM3JdOQQ0BCXIdwQiAvDNxZHncJZBYFk+9VNdeOsDSEkgqzdI6V8rMqvRrRoUv6hJMovLfUFAzo8LHkg1yGsEIgLzTs4cn5hJINKH8jAdnfMnSQz3WbIVdoeWknj08Uct3Kf9FoaDpGYC8NKvSr5Vzx8nnjb9kYzcx1clKnUTLSZT/olAwMwIgb3VdAomW12ElMbUzJyp1rJYIU/6LQkEwAiCvdV0CWTzt0pRKZFOdhbAzE5Mo98WJjfqAbEAwAqCgxMrPsCrVWQg7MzHxcl+c2KgPyBYEIwBgg51KnVAA8eCNl2nEgL5JzcSEcl/ilf8Cuc5jjMn6LSGDwaC8Xq8CgYDKysrcPh0ABS5UTSPFr9RxsjEZHViRi6w+vwlGACAJ8XYETnYWBMg3Vp/fLNMAQBLiNSsDYA/BCAAkKdVkWAAdaHoGAABcRTACAABcRTACAABcRTACAABcRTACAABcRTUNgLxBYzAgNxGMAMgL0ZqQOdkBFUD6sEwDIOeF2rN3DkQkqTHQpIXV+7TtYINLZwbACoIRAGnV1m5Ue/ikNh84ptrDJ9XW7uwOFG3tRlVb6qLuERM6VrWlzvGfC8A5LNMAiJprISnl/Asnl05i5YPsqT/VbUakMyOpIdCkPfWn6JYKZCmCEaDARQsY+l1QJEk683lr+JjdICK0dNJ1PiK0dLJy7jhbnxUrqGk+327pM46fjR2wAHAXyzRAAYuVa3Hm89aIQESyln8RWpLZtO9/9f1NBx1ZOkmUD/LRiXMJP0OSBpaWWBoHIPOYGQEKVLxci2iMJI86gogZFb5uSzbRZi/ifZaVpZNE+SAeSev3HJGvrESfBpuijvNI8nn/vPQEIPswMwIUqES5FtF0DiI6izV7kUiipRMr+SCNwWbdNXGYpI7Ao7PQ98vmVNBvBMhiBCNAgUolh6Lze+3OsHSWaOnE6jmOGHCBVs4dJ5838vN83hJbuSkA3MEyDVCgUsmh6PzeZGZYrC6dWD3HDz79TNdeOkA7/99U7f34NB1YgRxDMAIUqIkjy+X3lqgxED3XIppoQYTdGRY7SydWz/GpHR/qqR0fhitsbr3qYlvnBMBdLNMABapnD4+WzamQ1D3XIppYQYTdGRY7Syd2z5GOq0Bush2MvPHGG5ozZ44GDx4sj8ejX/3qVwnfs3PnTo0fP14lJSW65JJLtGrVqmTOFYDDZlX6o+Za9LugKNxrJCRWEBGavYgXLJT3LdJP77hK6+dP0psPT7OVwxHrHKOh4yqQm2wv05w7d05f+cpXdO+99+r2229POL6+vl4333yz5s+fr+rqar311lv6u7/7O1100UWW3g8gvWZV+jWjwpd0B9bQ7MXC6n3ySBHLKaHRP/rGlSklkXY+x7c+/D89teNwzLF0XAVyj+1gZPbs2Zo9e7bl8atWrdKwYcO0YsUKSdLo0aP1zjvv6Mc//jHBCGBDrHboTn1WtAe31Yd5aPaia58Rn4O75vbs4dHkUf0t56jQcRXIHWlPYK2trdXMmTMjjt10001avXq1WltbVVRU1O09zc3Nam5uDn8fDAbTfZpA2jgRRDi5x4uTn9VZrBkWp6tZrOao0HEVyB1pD0YaGxs1aNCgiGODBg3S+fPndeLECfn93f/yW758uaqqqtJ9akDapfLgDwUx2+sa9fxbH3V7Pdk9XpzaLyaa0OxFOiWqsKHjKpB7MlJN4/FE/svIGBP1eMjSpUsVCATCX0ePHk37OQJOS7SnSryKj20HG3Tdk6/rrud2Rw1EJPvJmolaq9v5LDfFq7Ch4yqQm9IejPh8PjU2NkYcO378uHr16qX+/aP/C6q4uFhlZWURX0AuSeXBb6e1eqz27NFYaa1u9bPcFqvCho6rQG5K+zLN5MmTtWXLlohjv/nNbzRhwoSo+SJAPrDz4O+8rJFsa3UryZr5lviZqRwVAOlnOxj57LPP9OGHH4a/r6+v14EDB1ReXq5hw4Zp6dKlOnbsmF544QVJ0oIFC/TUU09pyZIlmj9/vmpra7V69WqtX7/euasAskyyD/5kWqtL1pI1sznxM9kk30zkqABIP9vByDvvvKOpU6eGv1+yZIkkad68eVq7dq0aGhp05MiR8OsjR47Uq6++qgcffFBPP/20Bg8erJ/97GeU9SKvJfvgT6a1eqJkzdCDvjHwhcr79tbpcy1ZlfiZruoeALnDdjByww03hBNQo1m7dm23Y9dff7327dtn90cBOSvZig87sxJWkjWjPeiT/Swn+5x0Pr90VvcAyA1slAekgZWupNEe/HY2r0vUUCzWgz7Zz4o2e/Ho10brwr7FSQUoiZJ8PepI8p1R4SMPBMhzBCNAmiTTlTReEBPynWtH6MYKX9wHv5VE2PK+RXr0ljHylcUPImIFNQ2BJv3duv0Rx+z0UFn7Vn1SSb4A8g/BCJBGyVR8xApi7ORRWEmEPXWuVb6ykrgPervVPVaWV6wuHYXkSnUPgOQRjABplkzFR6plq06V8dqt7km0vGJn6Sjkg08/U+3hk5TtAnmMYATIUqmUrTpVxpvMrITTPVSe2vGhntrxIRU2QB7LSDt4AJkVSoSNNY/gUceyT6Iy3lR6jjjVQyXESht9ALmJYATIQ07t35IoqIkn1R4qXeXS/jkA7CEYAfJMW7tR7eGTaj7frgdu/JIGlSW/f0u8oCaWWLMuTnR2zaX9cwBYR84IkEeiVar4yor14I2XacSAvkk1K4tV3RNNKj1UPJK8fYp05ovWhOdEhQ2QX5gZAfJErN1+Pw02a8VrH6i4Vw9NHtU/qYqUWZV+vfnwNK2fP0n/dudVWj9/kp751jj5beyaa2Xp6N5rR1g6Hzf2zwGQPsyMAHkgE91Mo1X33FTpTA+VUCO4GRU+vfT2Udtt9AHkNoIRIA8kqlRJVzfTdPRQSaaNPoDcRjAC5AGnmpxlSrwgJpk2+gByG8EIkAecanKWLVLtQAsgtxCMAA5razcZf4haqVTJtVyLVDrQAsgtBCNACroGHqfPtejxrclvcJeseLv9kmsBINt5jDFZ38owGAzK6/UqEAiorKzM7dMBJFnffTb0+LfaaMzpc2JPFwBusfr8JhhBTnNjSUSyv/tsaJnkzYenpf383Pp/AgBdWX1+s0yDnOXWLEAyu8+mq7Q2VuBBrgWAXEIwgpwUa2YitLNrOpdEUtl91snSWpZkAOQL2sEj5yTqNiqld2fXVAIKp0prY7V+DwVj2w42OPJzACATCEaQc+x0G02HZAKKWDvZJsPtYAwAnMYyDXKO3W6jySZ0xnpfop4eXTldWutW63cASBeCEeQcO91Gk82rSPS+WD09onG6jXmutX4HgEQIRpBzrHYbPX2uRYvW2U9ytZocG23/FL+3RI9+bbQu7FucttLafGv9DgAEI8g5VrqNPvq10Xp8a+y8Co868ipmVPgiAoVE+Rid3+fW/in52PodQGEjgRU5KTQz4fNG/uvf5y3RyrnjdGHf4qSSXO0mx4Z6etx61cWaPKp/RpqLhYIx6c/BVwit3wHkImZGkLPizUxsPnDM0md0zavIlXyMWMtETuenAEAmEIwgp8XqNppsXkUu5WO4tUwEAE4jGIHjsmFvlGTzKnItH4PW7wDyAcEIHJUtLcqtJLlGy6tI9n0AgOSRwArH2GlR3tZuVHv4pDYfOKbawyfT0i00UZJrrOAo2fcBAJLjMcZkfc9oq1sQwz1t7UbXPfl6zEqU0PLGmw9P0/a6xozOnjjdgRUAYI3V5zfBCBxRe/ik7npud8JxD974Ja147f1u+RihRzwzDwCQP6w+v1mmgSOslrqueaueDd4AABEIRuAIq6WuZ75ojflaunfbBQBkJ6pp4AgrJbHePkVxg5EQtxuKxUMeCQA4j2AEjrBSEnvvtSP009c+SPhZ8WZZ3AwGnCxbJqgBgD8jGIFjErUon1Hh00tvH026oZibPUys7uRr9bO6/T8qK9ZdE4dpxIC+BCcACg7VNHBcvH/1hx7qUvTZk1gP9VjBQCaqcOyULScKIGJdR1duNIoDAKdRTQPXxNvJNpmGYm3tRlVb6lyrwrG7k28s8a6jq2iN4gAgX7FMg4yzu8GbnWAgHfu0OLWTb6Lr6MyoY8alakudZlT4WLIBkNcIRuAKKxu8hZZ7fm1xdiBdVThO7eRr9/zSHWQBQLYgGEHW6Jxr8tGJz7V+zxE1Bq0/wK0GDXY5tZNvsueXzaXOAOAEghFkhWgVJlZZDQbiiZd069ROvomCmljSFWQBQLYgGIHrrFaYRGMnGOgs0SxM12qWRGXLVqpe4gU1sa4t1SALAHIBpb1wVaKy2USSKYG1MgsTq2TYiWZlqfx8AMglVp/fzIzAVXYqTDr7m8nDNbvSbzsYsDoLE6uaxUribSJdq4mizczYmXEBgFxHMAJXJZucObvSbzsosNPnQ0pvNUvXoGbxtEtpDw+gYBGMwFV2kzNTyaNIdhYmE9UsTsy4AECuIhiBq+xUmFhNVo2V15FsUEE1CwCkF8EIYsrEzrJ2Kkys5FHE20wvk7MwAADrCEYQVSZ3yI1ZNmtzJ9tEO+s+/a2xjs/CAABSR2kvurGzQ66TsyepfJbVnXUf/VqFFq3rvmtwV+yaCwCpo7Q3B2ViWcTKOcTbIbdzuev2ukZLsydWryuVJE6rm+ld2Le3I7MwAADnEIxkCavLIlYe7KkENVYf6k+9/qFWvPZ+zCWR0OxJppZ77Oyse+tVF9vaNRgAkF4EI1kgUa6DnQd7qg9/qw/1NW/VJ5w9aW+XFq1LfF1OsLuzLqW0AJA9erh9AoUu0bKI1PFgf/X3HQFL11mL0IN928GGcFATb0wiVh/qZ75ojflaaPbkB5sPJryutnZnUpZCJcKx5jY86gjKqIwBgOxDMOIyq8siiR7sj73yBz32SuKgJtHD38pDvV+forifEXLqXEvM1zp3N3VCqERYUrdzpzIGALJbUsHIM888o5EjR6qkpETjx4/Xb3/725hja2pq5PF4un299957SZ90PrG6LJLowd4YbI7Y2yTaGCsPfysP9XuvHZHwfK1ysrtpqETY542c3fF5S9hwDgCymO2ckQ0bNuiBBx7QM888o2uvvVY///nPNXv2bNXV1WnYsGEx33fo0KGIsp6LLroouTPOQqkkjGa6u6eVh3/Mvh9/yj2ZUeHTS28fjdmvwyPpwr5FOnUu9lJOiNPX33UTOpJTASD72e4zcs0112jcuHFauXJl+Njo0aN12223afny5d3G19TUaOrUqTp9+rT69euX1Elmc5+RVBNGQ/0xnHiwW7F+/iTLiZvxgqxQfooU2a8j9Mh/+ltj9fjWP8a9Lp+3RG8+PI1AAQDylNXnt61lmpaWFu3du1czZ86MOD5z5kzt2rUr7nvHjh0rv9+v6dOna8eOHXHHNjc3KxgMRnxlIycSRq0si/zzrZUJ8zh8ZcXylTmbwBmqOLn1qos1eVT/iKAh0ZLIzV8eTA4HAMASW8s0J06cUFtbmwYNGhRxfNCgQWpsbIz6Hr/fr2effVbjx49Xc3OzXnzxRU2fPl01NTWaMmVK1PcsX75cVVVVdk4t4+w0B0v0wE20LDKr0q8ePTxR928JffJjXx8jSXHHOP3wT7QkYuW6AACwtUzzySef6OKLL9auXbs0efLk8PEf/vCHevHFFy0npc6ZM0cej0evvPJK1Nebm5vV3Nwc/j4YDGro0KFZtUxTe/ik7npud8JxTi2LSNaWhDK5p4xV2dBZFgCQeWlpBz9gwAD17Nmz2yzI8ePHu82WxDNp0iRVV1fHfL24uFjFxcV2Ti3j7HT8jCbWAzpe4GIlOTPWGKkjgHIjIKDBGAAgHlvBSO/evTV+/Hht375d3/jGN8LHt2/frltvvdXy5+zfv19+f25P0dvt+NlZKrMXVh7sXcdE+3nsxQIAyBa2S3uXLFmie+65RxMmTNDkyZP17LPP6siRI1qwYIEkaenSpTp27JheeOEFSdKKFSs0YsQIjRkzRi0tLaqurtbGjRu1ceNGZ68kw0LNwRJVi3RNGLXa+t0pMX9esFk/fe2D8PduL+UAAAqX7WDkjjvu0MmTJ/VP//RPamhoUGVlpV599VUNHz5cktTQ0KAjR46Ex7e0tOihhx7SsWPH1KdPH40ZM0Zbt27VzTff7NxVuCBUBWM1YbSt3Wj34ZN6ZOO7jiS9WhEvybardAVDAAAkYrvPiBtyvc9ItDHx2El6jcdqkm0IvT8AAE5KSwJrIeqaaDp++IXa+/Hp8PczKnxxk0pjLZPE41SLdLuf07llPAmnAIBMIRiJI9qMRg+P1HmvuXi5FnaWSTpzqkV6sp/j5H4xAAAkwq69McTqrtp109t43VYT7cjbVdcuqW3tRrWHT2rzgWOqPXwy4Y67XSXagTeWTO+XAwAobMyMRGFnRiNe4qmdGYauSa9ONC+Ll2Qb6xyiVQABAJBOzIxEYXdGo3OuRWd2Zhg6b3PvxJ43IbH2kOmK/WIAAG5hZiSKZHMmur4vUS8SSerXp0hP3z1Oky7p2IjOyT1vQrp2Zf3oxOdav+eIGoOR+8U8+rXR8vbprc0HjtEIDQCQMQQjUSSbM9H1fVZ6kTxx+5W69tIB4eOJZmWSrXjp2pV18bRLIyqATp9r0eNbs2tPGwBAYWCZJgq7iZ9dE087i7VM0nlZprNU97yxKhSc3HrVxQp80aJF65xZFgIAwC5mRjrp3FPkzquHacVr7ydM/LSSa2Flg7uQVPa8SUY6loUAALCDYORPolWv9LugSJJ05vPW8LGufUZ8Dm5wJyW/502y0rUsBACAVQQjit0lNfB5q4ykB2+8LLy7bdcOrE4nedrd8yZVmVoWAgAgloIPRqwsU7z09tGI/VrSPUMQyjPpOlNjdRbGjkwvCwEA0FXBByPZukxhJ88kFZleFgIAoKuCD0ayeZnCap5Jqj8jk8tCAAB0VfClvSxT2C8/BgDASQU/M8IyRYdMLQsBANBVwQcj6Vim6NyvJN0PdSd/ViaWhQAA6KrggxHJ2eoVJ3bbzcafBQBAuniMMYl2lnddMBiU1+tVIBBQWVlZ2n5OqrMMsfqVhD7ByfyLTP4sAACSYfX5XfAJrJ113q9l8qj+tpdm4vUrkTraqre1px77ZfJnAQCQbgQjDrHTrySXfhYAAOlGMOKQTPYryebeKAAA2FWwCaxOV7xksl8JvVEAAPmkIIORdFShZLJfiZu9UTJZtgwAKAwFt0wTqkLpmnPRGGjSwup92nawIanPDfUrkf5c0RLidFv1TP6szrYdbNB1T76uu57brftfOqC7ntut6558Pen/ZwAASAUWjKS7CiWTbdUz3cI9XUEcAAAFtUyTiR16M9lWPVM/K1EQ51FHEDejwseSDQDAtoIKRjJVhZLJtuqZ+FmZCOIAAIWroJZpqEJJDqXEAIB0KqhgJFSFEmshwaOOqpp836HXLoI4AEA6FVQw4lYVSq4jiAMApFNBBSNS5qtQ8gFBHAAgnQp2116ad9mXjmZxAID8ZfX5XbDBCJJDEAcAsMrq87ugSnuRukyWLQMACkPB5YwAAIDsQjACAABcRTACAABcRTACAABcRTACAABcRTACAABcRTACAABcRTACAABcRTACAABclRMdWEMd64PBoMtnAgAArAo9txPtPJMTwcjZs2clSUOHDnX5TAAAgF1nz56V1+uN+XpObJTX3t6uTz75RKWlpfJ4nNuULRgMaujQoTp69GjebsCX79fI9eW+fL/GfL8+Kf+vketLnjFGZ8+e1eDBg9WjR+zMkJyYGenRo4eGDBmSts8vKyvLyz9gneX7NXJ9uS/frzHfr0/K/2vk+pITb0YkhARWAADgKoIRAADgqoIORoqLi7Vs2TIVFxe7fSppk+/XyPXlvny/xny/Pin/r5HrS7+cSGAFAAD5q6BnRgAAgPsIRgAAgKsIRgAAgKsIRgAAgKvyPhj54Q9/qK9+9au64IIL1K9fP0vvMcboscce0+DBg9WnTx/dcMMN+sMf/hAxprm5Wffdd58GDBigvn376utf/7r+93//Nw1XEN/p06d1zz33yOv1yuv16p577tGZM2fivsfj8UT9+pd/+ZfwmBtuuKHb63feeWear6a7ZK7v29/+drdznzRpUsSYbLl/kv1rbG1t1cMPP6wrr7xSffv21eDBg/U3f/M3+uSTTyLGuXUPn3nmGY0cOVIlJSUaP368fvvb38Ydv3PnTo0fP14lJSW65JJLtGrVqm5jNm7cqIqKChUXF6uiokKbNm1K1+lbYucaX375Zc2YMUMXXXSRysrKNHnyZP3Xf/1XxJi1a9dG/Z1sampK96VEZef6ampqop77e++9FzEum+6hneuL9veJx+PRmDFjwmOy6f698cYbmjNnjgYPHiyPx6Nf/epXCd+TFb+DJs/94z/+o/nJT35ilixZYrxer6X3PPHEE6a0tNRs3LjRvPvuu+aOO+4wfr/fBIPB8JgFCxaYiy++2Gzfvt3s27fPTJ061XzlK18x58+fT9OVRDdr1ixTWVlpdu3aZXbt2mUqKyvNLbfcEvc9DQ0NEV/PP/+88Xg85vDhw+Ex119/vZk/f37EuDNnzqT7crpJ5vrmzZtnZs2aFXHuJ0+ejBiTLffPGPvXeObMGXPjjTeaDRs2mPfee8/U1taaa665xowfPz5inBv38KWXXjJFRUXmueeeM3V1deb+++83ffv2NR9//HHU8f/zP/9jLrjgAnP//feburo689xzz5mioiLzn//5n+Exu3btMj179jQ/+tGPzB//+Efzox/9yPTq1cvs3r07rdcSi91rvP/++82TTz5p9uzZY95//32zdOlSU1RUZPbt2xces2bNGlNWVtbtd9MNdq9vx44dRpI5dOhQxLl3/l3Kpnto9/rOnDkTcV1Hjx415eXlZtmyZeEx2XT/Xn31VfMP//APZuPGjUaS2bRpU9zx2fI7mPfBSMiaNWssBSPt7e3G5/OZJ554InysqanJeL1es2rVKmNMxx/OoqIi89JLL4XHHDt2zPTo0cNs27bN8XOPpa6uzkiK+ANRW1trJJn33nvP8ufceuutZtq0aRHHrr/+enP//fc7dapJSfb65s2bZ2699daYr2fL/TPGuXu4Z88eIyniL1Q37uHEiRPNggULIo5dccUV5pFHHok6/nvf+5654oorIo797d/+rZk0aVL4+29+85tm1qxZEWNuuukmc+eddzp01vbYvcZoKioqTFVVVfh7q38/ZYLd6wsFI6dPn475mdl0D1O9f5s2bTIej8d89NFH4WPZdP86sxKMZMvvYN4v09hVX1+vxsZGzZw5M3ysuLhY119/vXbt2iVJ2rt3r1pbWyPGDB48WJWVleExmVBbWyuv16trrrkmfGzSpEnyer2Wz+PTTz/V1q1b9Z3vfKfba//xH/+hAQMGaMyYMXrooYfCuydnSirXV1NTo4EDB+pLX/qS5s+fr+PHj4dfy5b7JzlzDyUpEAjI4/F0W4rM5D1saWnR3r17I/6/StLMmTNjXkttbW238TfddJPeeecdtba2xh2T6XslJXeNXbW3t+vs2bMqLy+POP7ZZ59p+PDhGjJkiG655Rbt37/fsfO2KpXrGzt2rPx+v6ZPn64dO3ZEvJYt99CJ+7d69WrdeOONGj58eMTxbLh/yciW38Gc2CgvkxobGyVJgwYNijg+aNAgffzxx+ExvXv31oUXXthtTOj9mdDY2KiBAwd2Oz5w4EDL5/GLX/xCpaWl+qu/+quI43fffbdGjhwpn8+ngwcPaunSpfrd736n7du3O3LuViR7fbNnz9Zf//Vfa/jw4aqvr9ejjz6qadOmae/evSouLs6a+yc5cw+bmpr0yCOP6Fvf+lbEJleZvocnTpxQW1tb1N+dWNfS2NgYdfz58+d14sQJ+f3+mGMyfa+k5K6xq3/913/VuXPn9M1vfjN87IorrtDatWt15ZVXKhgM6t/+7d907bXX6ne/+50uu+wyR68hnmSuz+/369lnn9X48ePV3NysF198UdOnT1dNTY2mTJkiKfZ9zvQ9TPX+NTQ06Ne//rXWrVsXcTxb7l8ysuV3MCeDkccee0xVVVVxx7z99tuaMGFC0j/D4/FEfG+M6XasKytjrLB6fVL387R7Hs8//7zuvvtulZSURByfP39++L8rKyt12WWXacKECdq3b5/GjRtn6bNjSff13XHHHeH/rqys1IQJEzR8+HBt3bq1W9Bl53PtyNQ9bG1t1Z133qn29nY988wzEa+l8x7GY/d3J9r4rseT+X1Mp2TPZ/369Xrssce0efPmiCB00qRJEUnW1157rcaNG6d///d/189+9jPnTtwiO9d3+eWX6/LLLw9/P3nyZB09elQ//vGPw8GI3c9Mt2TPZe3aterXr59uu+22iOPZdv/syobfwZwMRhYvXpywKmDEiBFJfbbP55PUES36/f7w8ePHj4cjQ5/Pp5aWFp0+fTriX9fHjx/XV7/61aR+bmdWr+/3v/+9Pv30026v/d///V+3KDaa3/72tzp06JA2bNiQcOy4ceNUVFSkDz74IOUHWaauL8Tv92v48OH64IMPJKX//kmZucbW1lZ985vfVH19vV5//fWEW387eQ+jGTBggHr27NntX0udf3e68vl8Ucf36tVL/fv3jzvGzp8BpyRzjSEbNmzQd77zHf3yl7/UjTfeGHdsjx49dPXVV4f/zGZKKtfX2aRJk1RdXR3+PlvuYSrXZ4zR888/r3vuuUe9e/eOO9at+5eMrPkddCz7JMvZTWB98sknw8eam5ujJrBu2LAhPOaTTz5xLYH1v//7v8PHdu/ebTn5cd68ed0qMGJ59913jSSzc+fOpM/XrlSvL+TEiROmuLjY/OIXvzDGZM/9Myb5a2xpaTG33XabGTNmjDl+/Liln5WJezhx4kSzcOHCiGOjR4+Om8A6evToiGMLFizoljw3e/bsiDGzZs1yNYHVzjUaY8y6detMSUlJwmTCkPb2djNhwgRz7733pnKqSUnm+rq6/fbbzdSpU8PfZ9M9TPb6Qom67777bsKf4eb960wWE1iz4Xcw74ORjz/+2Ozfv99UVVWZv/iLvzD79+83+/fvN2fPng2Pufzyy83LL78c/v6JJ54wXq/XvPzyy+bdd981d911V9TS3iFDhpjXXnvN7Nu3z0ybNs210t4vf/nLpra21tTW1porr7yyW1lo1+szxphAIGAuuOACs3Llym6f+eGHH5qqqirz9ttvm/r6erN161ZzxRVXmLFjx2b99Z09e9b8/d//vdm1a5epr683O3bsMJMnTzYXX3xxVt4/Y+xfY2trq/n6179uhgwZYg4cOBBRStjc3GyMce8ehsomV69eberq6swDDzxg+vbtG648eOSRR8w999wTHh8qK3zwwQdNXV2dWb16dbeywrfeesv07NnTPPHEE+aPf/yjeeKJJ7KitNfqNa5bt8706tXLPP300zHLrB977DGzbds2c/jwYbN//35z7733ml69ekUEqdl6fT/96U/Npk2bzPvvv28OHjxoHnnkESPJbNy4MTwmm+6h3esLmTt3rrnmmmuifmY23b+zZ8+Gn3OSzE9+8hOzf//+cKVdtv4O5n0wMm/ePCOp29eOHTvCYySZNWvWhL9vb283y5YtMz6fzxQXF5spU6Z0i4a/+OILs3jxYlNeXm769OljbrnlFnPkyJEMXdWfnTx50tx9992mtLTUlJaWmrvvvrtbiV3X6zPGmJ///OemT58+UftOHDlyxEyZMsWUl5eb3r17m1GjRpnvfve73Xp1ZILd6/v888/NzJkzzUUXXWSKiorMsGHDzLx587rdm2y5f8bYv8b6+vqof6Y7/7l28x4+/fTTZvjw4aZ3795m3LhxETMx8+bNM9dff33E+JqaGjN27FjTu3dvM2LEiKgB8i9/+Utz+eWXm6KiInPFFVdEPOjcYOcar7/++qj3at68eeExDzzwgBk2bJjp3bu3ueiii8zMmTPNrl27MnhFkexc35NPPmlGjRplSkpKzIUXXmiuu+46s3Xr1m6fmU330O6f0TNnzpg+ffqYZ599NurnZdP9C83gxPrzlq2/gx5j/pSpAgAA4AL6jAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFcRjAAAAFf9f48SQ7T11FdvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.linspace(-1, 1, 100)\n",
    "# In the given example, torch.linspace(-1, 1, 100) creates a tensor x with 100 elements that are linearly \n",
    "# spaced between -1 and 1 (inclusive). The range -1 to 1 is divided into 100 equally spaced points.\n",
    "# So, I have 100 examples in this case. \n",
    "y = f(x)\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a trainable function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will attempt to approximate $f$ using a differentiable parameterized function $\\hat{f}$ with much fewer parameters than the number of examples.\n",
    "\n",
    "> Worth discussing with your friends: Why do we want much fewer parameters than the number of examples? \n",
    "\n",
    "#### Is it bc we need to adjust these parameters to fit the data set, so the least parameters we can use to adjust the data set, the better in terms of computing efficiency?.. not really bc we can use multiple threads to make it faster.. \n",
    "\n",
    "We will train parameters $\\theta$ for $\\hat{f}$ to minimize some differentiable loss function $L$ between $\\hat{f}(x)$ and $y$ for all observations $(x, y)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a function such that we can repeatedly adjust $\\theta$ against the gradient of $L$ with respect to $\\theta$, at some learning rate $\\lambda$. That is,\n",
    "\n",
    "Do $\\quad \\theta \\gets \\theta - \\lambda \\nabla_\\theta L(\\hat{f}(x), y) \\quad$ for all $(x, y)$ repeatedly until it's good enough.\n",
    "\n",
    "Typical artificial neural networks (ANNs) are functions that allow us to do that. Let's make one kind of ANN called a multilayer perceptron (MLP), also called a feedforward neural network, also called a fully connected neural network.\n",
    "\n",
    "For now, let $\\hat{f}$ be an MLP that takes a **single scalar** input $x$ and outputs a number $\\hat{y}$. We will make it handle a batch of inputs later.\n",
    "\n",
    "I'M GUESSING WHAT I DON'T UNDERSTAND IS WHY DO WE NEED TO FOLLOW THESE THREE STEPS TO GET THIS F_HAT FUNCTION (FUNCTION THAT APPROXIMATES THE TARGET)... This is specificially for ANN, you want to introduce non linearlity so that the model can better learn (?) to adjust to the data? or can just better adjust to the data? \n",
    "\n",
    "Here is what will happen inside.\n",
    "1. We apply a linear transformation. (to the scalar input)\n",
    "2. We apply a nonlinear transformation.\n",
    "3. We apply a linear transformation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the **first linear transformation**, we will multiply $x$ by a vector of 4 weights $\\mathbf{W_1}$, and then add a vector of 4 biases $\\mathbf{B_1}$ to that. I've given these parameters the subscript $\\mathbf{_1}$ because they belong to the 1st linear transformation. Both $\\mathbf{W_1}$ and $\\mathbf{B_1}$ will be shaped $4 \\times 1$. Let's call the result $\\mathbf{Z}$.\n",
    "\n",
    "$\\mathbf{Z} = \\mathbf{W_1} x + \\mathbf{B_1}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply a **nonlinear transformation** to $\\mathbf{z}$. There are many we can choose from, but we usually use the rectified linear unit (ReLU). It's just a function that returns the max of 0 and the input.\n",
    "\n",
    "$\\mathrm{ReLU}(z) = \\max(0, z)$\n",
    "\n",
    "Let's apply it element-wise to $\\mathbf{Z}$ and call the result $\\mathbf{A}$ for \"activation.\"\n",
    "\n",
    "$\\mathbf{A} = \\mathrm{ReLU}(\\mathbf{Z})$\n",
    "\n",
    "Because machine learning (ML) people tend to use brain analogies, 4 elements in $\\mathbf{A}$ are often called *neurons*, i.e. there are 4 neurons in this layer. They're also called *hidden units*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the **second linear transformation**. $\\mathbf{A}$ is a $4 \\times 1$ matrix. Since we want a single-element output, we must multiply it by a $1 \\times 4$ matrix $\\mathbf{W_2}$ and then add a $1 \\times 1$ matrix $\\mathbf{B_2}$.\n",
    "\n",
    "$\\hat{y} = \\mathbf{W_2 A} + \\mathbf{B_2}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batching is an essential component in modern machine learning because it allows us to train functions quickly by leveraging parallel multiprocessors, i.e. graphics processing units (GPUs)... I'm assuming diff threads run diff batches\n",
    "\n",
    "I NEED TO WRITE DOWN WHAT'S BELOW TO ACTUALLY VISUALIZE IT!!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we want $\\hat{f}$ to take a batch of inputs $\\mathbf{X}$. We need to consider what shape $\\mathbf{X}$ should be. The convention is to make the first dimension the batch dimension, followed by the shape of a single $x$. Since our $x$ is just a single number, our $\\mathbf{X}$ is shaped $(\\mathrm{batch\\ size} \\times 1)$. We also want $\\hat{\\mathbf{Y}}$, the batch of outputs from $\\hat{f}$, to have the batch dimension first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we transpose the $\\mathbf{W}$ s, so that $\\mathbf{W_1}$ is shaped $1 \\times 4$ and $\\mathbf{W_2}$ is shaped $4 \\times 1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we change $\\hat{f}$ thus:\n",
    "> Instead of multiplying $\\mathbf{W_1}x$, we do $\\mathbf{XW_1}$.\n",
    "\n",
    "> Instead of multiplying $\\mathbf{W_2 A}$, we do $\\mathbf{AW_2}$.\n",
    "\n",
    "Then $\\hat{\\mathbf{Y}}$ will be shaped $(\\mathrm{batch\\ size} \\times 1)$. You can ponder about it and work out a few examples until you're convinced."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's write it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure $\\mathbf{X}$ and $\\mathbf{Y}$ are the shape we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100]), torch.Size([100]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now they're 1-dimensional arrays. We want to make them 2-dimensional by adding a second dimension of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[:, None]\n",
    "y = y[:, None]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1]), torch.Size([100, 1]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then write $\\hat{f}$.\n",
    "\n",
    "First, write a linear function that returns $\\mathbf{Z}$ from $x$. It should be about one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(x: torch.Tensor, w1: torch.Tensor, b1: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :returns: z\n",
    "\n",
    "    I usually write better docstrings, but that would just give you the solution.\n",
    "    \"\"\"\n",
    "    return  x @ w1 + b1 # multiply matrices, then add bias... check the dimensions of the matrices, bias later "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'return x @ w1 + b1'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(b'cmV0dXJuIHggQCB3MSArIGIx').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the nonlinear function that returns $\\mathbf{A}$. Take $\\mathbf{Z}$ as input. One line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear(z: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :returns: a\n",
    "    \"\"\"\n",
    "    return torch.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'return torch.relu(z)'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(b'cmV0dXJuIHRvcmNoLnJlbHUoeik=').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement the second linear function that returns $\\hat{y}$. Take $\\mathbf{A}$ as input. One line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear2(a: torch.Tensor, w2: torch.Tensor, b2: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :returns: y hat\n",
    "    \"\"\"\n",
    "    return a @ w2 + b2 # w2 @ a + b2 or  a @ w2 + b2??????????????????????????????????????????????????? a bc if the explanation above \n",
    "# I want that the first dimension of y_hat has batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'return a @ w2 + b2'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(b'cmV0dXJuIGEgQCB3MiArIGIy').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write $\\hat{f}$ as a composition of the first linear, the nonlinear, and the second linear functions. Instead of just returning $\\hat{y}$, we're going to also return $\\mathbf{Z}$ and $\\mathbf{A}$ so we can use them to calculate gradients later. This should take about 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_hat(x: torch.Tensor, \n",
    "          w1: torch.Tensor, \n",
    "          b1: torch.Tensor,\n",
    "          w2: torch.Tensor, \n",
    "          b2: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    :returns: a tuple (z, a, y hat)\n",
    "    \"\"\"\n",
    "    # \n",
    "    z = linear1(x, w1, b1)\n",
    "    a = nonlinear(z)\n",
    "    y_hat = linear2(a, w2, b2)\n",
    "\n",
    "    return z, a, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = linear1(x, w1, b1)\n",
      "a = nonlinear(z)\n",
      "return z, a, linear2(a, w2, b2)\n"
     ]
    }
   ],
   "source": [
    "print(base64.b64decode(b'eiA9IGxpbmVhcjEoeCwgdzEsIGIxKQphID0gbm9ubGluZWFyKHopCnJldHVybiB6LCBhLCBsaW5lYXIyKGEsIHcyLCBiMik=').decode())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our loss function, we can use the mean squared error $L = \\text{MSE}(\\hat{\\mathbf{Y}}, \\mathbf{Y}) = \\dfrac{\\sum_{i=1}^{|\\mathbf{Y}|}(\\hat{\\mathbf{Y}_i} - \\mathbf{Y}_i)^2}{|\\mathbf{Y}|}$. I'll write this one for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param y_hat: predictions\n",
    "    :param y: labels\n",
    "    :returns: the mean squared error between y_hat and y.\n",
    "\n",
    "\n",
    "\n",
    "    The code you provided calculates the mean squared error (MSE) between the predicted values (y_hat) and the target \n",
    "    values (y). It doesn't require a loop because it operates on tensors, which can perform element-wise operations \n",
    "    efficiently without the need for explicit loops. In this case, y_hat - y calculates the difference between the \n",
    "    predicted values and the target values for each corresponding element in the tensors. \n",
    "    The expression (y_hat - y) ** 2 squares each element-wise difference, and .mean() computes the mean of all \n",
    "    squared differences, giving you the average MSE. By performing these operations directly on tensors, you leverage \n",
    "    the efficiency of tensor operations and can avoid the need for an explicit loop. The calculations are automatically\n",
    "    applied element-wise across the tensors, allowing for faster computation compared to a loop-based implementation.\n",
    "    \"\"\"\n",
    "    return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap,\n",
    "> We wanted a differentiable parameterized function that could approximate $f$. We now have this as $\\hat{f}$.\n",
    "\n",
    "> We also wanted a differentiable function that could capture the error between the output of $\\hat{f}$ and the output of $f$. We now have this as $L$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know how to adjust the parameters, we must find the gradient of the loss function with respect to each parameter. Once we find that, we just nudge the parameters in a direction that decreases the loss. Because we can step backwards through the operations using the chain rule, this is called *backpropagation*, while applying $\\hat{f}$ is called *forward propagation*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the gradients from the back. In order to go from $L$ to all the parameters, we have to go through $\\hat{y}$. What's $\\nabla_{\\hat{y}} L$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<>:7: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "/var/folders/rt/9z20cljs78966f3n2r99gzsw0000gn/T/ipykernel_1501/4274234860.py:7: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "  return (1/y_hat.shape[0])*2(y_hat - y)\n"
     ]
    }
   ],
   "source": [
    "def d_loss_wrt_y_hat(y_hat: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param y_hat: predictions\n",
    "    :param y: labels\n",
    "    :returns: the derivative of the loss with respect to the predictions.\n",
    "    \"\"\"\n",
    "    return (1/y_hat.shape[0])*2(y_hat - y)\n",
    "# so, the length of y and y_hat is the same??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'return 2 * (y_hat - y)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(b'cmV0dXJuIDIgKiAoeV9oYXQgLSB5KQ==').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have the $\\mathbf{W_2}$ and $\\mathbf{B_2}$ in our sights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_y_hat_wrt_w2(a: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param a: output of the nonlinear function\n",
    "    :returns: the derivative of the second linear function with respect to w2.\n",
    "    \"\"\"\n",
    "    # only the derivative of y_hat = AW2+B2 (no the derivative of the cost function when y_hat is the \n",
    "    # aforementioned expression)\n",
    "    return a.sum(0)\n",
    "\n",
    "\n",
    "# The 0 argument passed to sum indicates the dimension along which the summation is performed. In this case, 0 refers \n",
    "# to axis 0, which is the first dimension of a. Therefore, a.sum(0) calculates the sum of elements along axis 0.\n",
    "\n",
    "# The result of a.sum(0) is a tensor that contains the sum of elements along axis 0. The specific shape and size of the \n",
    "# resulting tensor depend on the original shape and size of a.\n",
    "\n",
    "# The returned value of a.sum(0) represents the derivative of the second linear function with respect to w2. \n",
    "# By summing along axis 0, it effectively computes the total effect of the elements of a on the derivative with \n",
    "# respect to w2.\n",
    "\n",
    "def d_y_hat_wrt_b2() -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :returns: the derivative of the second linear function with respect to b2.\n",
    "    \"\"\"\n",
    "    return 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although $\\mathbf{A}$ is not a parameter, we have to go through it in order to get to the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_y_hat_wrt_a(w2: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :returns: the derivative of the second linear function with respect to a.\n",
    "    \"\"\"\n",
    "    return w2.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{A}$ was the output of the nonlinear function, i.e. ReLU. Although in pure math, ReLU is not differentiable, we treat its derivative as 1 if its input is greater than 0 and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_a_wrt_z(z: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param z: the output of the first linear function\n",
    "    :returns: the derivative of ReLU with respect to z\n",
    "    \"\"\"\n",
    "    return z > 0 # this is a boolean tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base64.b64decode(b'cmV0dXJuIHogPiAw').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From $\\mathbf{Z}$, we can see $\\mathbf{W_1}$ and $\\mathbf{B_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_z_wrt_w1(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param x: input examples\n",
    "    :returns: the derivative of the first linear function with respect to w1\n",
    "    \"\"\"\n",
    "    return x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_z_wrt_b1() -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    :param x: input examples\n",
    "    :returns: the derivative of the first linear function with respect to b1\n",
    "    \"\"\"\n",
    "    return 1\n",
    "\n",
    "# if you want the derivate of anything respect of sth, you want to cast it (the shape)n of that sth "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this information, we can repeatedly update\n",
    "* $\\mathbf{W_2} \\gets \\mathbf{W_2} - \\lambda \\nabla_{\\mathbf{W_2}} L$\n",
    "* $\\mathbf{B_2} \\gets \\mathbf{B_2} - \\lambda \\nabla_{\\mathbf{B_2}} L$\n",
    "* $\\mathbf{W_1} \\gets \\mathbf{W_1} - \\lambda \\nabla_{\\mathbf{W_1}} L$\n",
    "* $\\mathbf{B_1} \\gets \\mathbf{B_1} - \\lambda \\nabla_{\\mathbf{B_1}} L$\n",
    "\n",
    "\n",
    "until we approach the capability of $\\hat{f}$ to approximate $f$. This update size is controlled by a usually small learning rate $\\lambda$ that gets smaller over time. Here, we'll just keep it constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following function, fill in these gradients.\n",
    "* $\\nabla_{\\mathbf{W_2}} L$\n",
    "* $\\nabla_{\\mathbf{B_2}} L$\n",
    "* $\\nabla_{\\mathbf{W_1}} L$\n",
    "* $\\nabla_{\\mathbf{B_1}} L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "def update_parameters(z: torch.Tensor,\n",
    "                      a: torch.Tensor,\n",
    "                      y_hat: torch.Tensor,\n",
    "                      y: torch.Tensor,\n",
    "                      w1: torch.Tensor,\n",
    "                      b1: torch.Tensor,\n",
    "                      w2: torch.Tensor,\n",
    "                      b2: torch.Tensor) -> tuple[torch.Tensor, ...]:\n",
    "    \"\"\"\n",
    "    Update the parameters by nudging them against the gradient of the loss with respect to the parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    d_loss_wrt_w2 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_w2(a)).mean(0)\n",
    "    d_loss_wrt_b2 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_b2()).mean(0)\n",
    "    d_loss_wrt_w1 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_a(w2) * d_a_wrt_z(z) * d_z_wrt_w1(x)).mean(0)\n",
    "    d_loss_wrt_b1 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_a(w2) * d_a_wrt_z(z) * d_z_wrt_b1()).mean(0)\n",
    "\n",
    "    w2 -= LEARNING_RATE * d_loss_wrt_w2[:, None]\n",
    "    b2 -= LEARNING_RATE * d_loss_wrt_b2\n",
    "    w1 -= LEARNING_RATE * d_loss_wrt_w1[None, :]\n",
    "    b1 -= LEARNING_RATE * d_loss_wrt_b1\n",
    "\n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "# IMPORT TENSORBOARD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following cell for a hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use the chain rule.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(b'VXNlIHRoZSBjaGFpbiBydWxlLg==').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base64.b64decode(b'VGhlIGRlcml2YXRpdmUgb2YgYSBtZWFuIGlzIHRoZSBtZWFuIGRlcml2YXRpdmUu').decode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "d_loss_wrt_w2 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_w2(a)).mean(0)\n",
      "d_loss_wrt_b2 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_b2()).mean(0)\n",
      "d_loss_wrt_w1 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_a(w2) * d_a_wrt_z(z) * d_z_wrt_w1(x)).mean(0)\n",
      "d_loss_wrt_b1 = (d_loss_wrt_y_hat(y_hat, y) * d_y_hat_wrt_a(w2) * d_a_wrt_z(z) * d_z_wrt_b1()).mean(0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " print(base64.b64decode(b'CmRfbG9zc193cnRfdzIgPSAoZF9sb3NzX3dydF95X2hhdCh5X2hhdCwgeSkgKiBkX3lfaGF0X3dydF93MihhKSkubWVhbigwKQpkX2xvc3Nfd3J0X2IyID0gKGRfbG9zc193cnRfeV9oYXQoeV9oYXQsIHkpICogZF95X2hhdF93cnRfYjIoKSkubWVhbigwKQpkX2xvc3Nfd3J0X3cxID0gKGRfbG9zc193cnRfeV9oYXQoeV9oYXQsIHkpICogZF95X2hhdF93cnRfYSh3MikgKiBkX2Ffd3J0X3ooeikgKiBkX3pfd3J0X3cxKHgpKS5tZWFuKDApCmRfbG9zc193cnRfYjEgPSAoZF9sb3NzX3dydF95X2hhdCh5X2hhdCwgeSkgKiBkX3lfaGF0X3dydF9hKHcyKSAqIGRfYV93cnRfeih6KSAqIGRfel93cnRfYjEoKSkubWVhbigwKQo=').decode())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the gradient descent function. We will first initialize the parameters: the $\\mathbf{W}$ s randomly and the $\\mathbf{B}$ s to $\\mathbf{0}$. Then start a loop for a number of iterations, called *epochs*, which is often decided beforehand, applying the updates to these parameters after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50000\n",
    "N_HIDDEN_UNITS = 4\n",
    "\n",
    "w1 = torch.randn(1, N_HIDDEN_UNITS)\n",
    "b1 = torch.zeros(N_HIDDEN_UNITS)\n",
    "w2 = torch.randn(N_HIDDEN_UNITS, 1)\n",
    "b2 = torch.zeros(1)\n",
    "\n",
    "def gradient_descent(w1: torch.Tensor, \n",
    "                     b1: torch.Tensor, \n",
    "                     w2: torch.Tensor, \n",
    "                     b2: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Optimize parameters through gradient descent.\n",
    "    \"\"\"\n",
    "    \n",
    "    for _ in (progress_bar := tqdm.tqdm(range(N_EPOCHS), desc=\"training\")):\n",
    "        z, a, y_hat = f_hat(x, w1, b1, w2, b2)\n",
    "        w1, b1, w2, b2 = update_parameters(z, a, y_hat, y, w1, b1, w2, b2)\n",
    "        progress_bar.set_postfix_str(f\"loss: {loss(y_hat, y)}\")\n",
    "\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With just random parameters, $\\hat{f}$ shouldn't be good at approximating $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(x.cpu().numpy(), y)\n",
    "plt.plot(x.cpu().numpy(), \n",
    "         f_hat(x, w1, b1, w2, b2)[2].cpu().numpy(), \n",
    "         color=\"red\", \n",
    "         label=\"random parameters\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1, w2, b2 = gradient_descent(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(x.cpu().numpy(), y)\n",
    "plt.plot(x.cpu().numpy(), \n",
    "         f_hat(x, w1, b1, w2, b2)[2].cpu().numpy(), \n",
    "         color=\"red\", \n",
    "         label=\"trained parameters\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent (SGD) is just gradient descent, but instead of updating parameters after looking at all examples, you update them after looking at a smaller batch of them, called a minibatch, or just a batch. This may be necessary when all training data can't fit into your memory. An epoch is counted when you look at all examples once.\n",
    "\n",
    "Suppose we use minibatches of size 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training with SGD, you should shuffle your training data, just in case there's some order to them that would cause weird training behavior. The PyTorch way to do this is to create a PyTorch `Dataset` out of the data, and load it into your training loop with a `DataLoader`, which takes care of shuffling it every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(data.TensorDataset(x, y), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(\n",
    "        w1: torch.Tensor, \n",
    "        b1: torch.Tensor, \n",
    "        w2: torch.Tensor, \n",
    "        b2: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Optimize parameters through stochastic gradient descent.\n",
    "    \"\"\"\n",
    "    for _ in (progress_bar := tqdm.tqdm(range(N_EPOCHS), desc=\"training\")):\n",
    "        for x, y in dataloader:\n",
    "            z, a, y_hat = f_hat(x, w1, b1, w2, b2)\n",
    "            w1, b1, w2, b2 = update_parameters(z, a, y_hat, y, w1, b1, w2, b2)\n",
    "            progress_bar.set_postfix_str(f\"minibatch loss: {loss(y_hat, y)}\")\n",
    "\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reinitialize the parameters and try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(1, N_HIDDEN_UNITS)\n",
    "b1 = torch.zeros(N_HIDDEN_UNITS)\n",
    "w2 = torch.randn(N_HIDDEN_UNITS, 1)\n",
    "b2 = torch.zeros(1)\n",
    "\n",
    "w1, b1, w2, b2 = stochastic_gradient_descent(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(x.cpu().numpy(), y)\n",
    "plt.plot(x.cpu().numpy(), \n",
    "         f_hat(x, w1, b1, w2, b2)[2].cpu().numpy(), \n",
    "         color=\"red\", \n",
    "         label=\"trained parameters\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zugzwang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
